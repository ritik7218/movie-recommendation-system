{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyONXq3rn0Tu9c8K0qQuBHp4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"53430f8b82c5465c803dd2927e70bd0a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a46cfa4d155c49308bfc1fb1be4a3532","IPY_MODEL_027516baa2b440719fb09fa0ebb87989","IPY_MODEL_52e65dcd5bc349c79f1554130341fad2"],"layout":"IPY_MODEL_54f97b8f351c46b4a2d2d33e4dd08a2c"}},"a46cfa4d155c49308bfc1fb1be4a3532":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82b2629549dd4611893d34478564dabe","placeholder":"​","style":"IPY_MODEL_3979b3ff99414539a2b4482f80e74483","value":"100%"}},"027516baa2b440719fb09fa0ebb87989":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_67d6e0d1c47c4d0db8640b11ef0bfb99","max":128,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d3a806a92cfb4cb5a8d1b35c12cdbd5f","value":128}},"52e65dcd5bc349c79f1554130341fad2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_637c64d3522947cf9426b72a693a121c","placeholder":"​","style":"IPY_MODEL_ae376510ddbe4e3cb522d33f69fed632","value":" 128/128 [03:09&lt;00:00,  1.49s/it]"}},"54f97b8f351c46b4a2d2d33e4dd08a2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82b2629549dd4611893d34478564dabe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3979b3ff99414539a2b4482f80e74483":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67d6e0d1c47c4d0db8640b11ef0bfb99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3a806a92cfb4cb5a8d1b35c12cdbd5f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"637c64d3522947cf9426b72a693a121c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae376510ddbe4e3cb522d33f69fed632":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["# import the dataset\n","import pandas as pd\n","movies_df = pd.read_csv('data/ml-latest-small/movies.csv')\n","ratings_df = pd.read_csv('data/ml-latest-small/ratings.csv')"],"metadata":{"id":"oI5IU3jOz6GU","executionInfo":{"status":"ok","timestamp":1687936264912,"user_tz":-330,"elapsed":401,"user":{"displayName":"Ritik Maurya","userId":"07333108638949409589"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["import zipfile\n","with zipfile.ZipFile('ml-latest-small.zip', 'r') as zip_ref:\n","    zip_ref.extractall('data')"],"metadata":{"id":"GnxSKP5vz1Fu","executionInfo":{"status":"ok","timestamp":1687936261729,"user_tz":-330,"elapsed":402,"user":{"displayName":"Ritik Maurya","userId":"07333108638949409589"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"ycBJIlCa6h2I"}},{"cell_type":"code","source":["print('The dimensions of movies dataframe are:', movies_df.shape,'\\nThe dimensions of ratings dataframe are:', ratings_df.shape)\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qzI1e3p4z-OO","executionInfo":{"status":"ok","timestamp":1687935791641,"user_tz":-330,"elapsed":366,"user":{"displayName":"Ritik Maurya","userId":"07333108638949409589"}},"outputId":"4535b93a-72f0-4b19-db67-11a8f2401a87"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["The dimensions of movies dataframe are: (9742, 3) \n","The dimensions of ratings dataframe are: (100836, 4)\n"]}]},{"cell_type":"code","source":["# Take a look at movies_df\n","movies_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"yhxzML-h0Dxq","executionInfo":{"status":"ok","timestamp":1687935805465,"user_tz":-330,"elapsed":405,"user":{"displayName":"Ritik Maurya","userId":"07333108638949409589"}},"outputId":"231cefc5-9ee5-4e82-848b-b206e8822687"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   movieId                               title  \\\n","0        1                    Toy Story (1995)   \n","1        2                      Jumanji (1995)   \n","2        3             Grumpier Old Men (1995)   \n","3        4            Waiting to Exhale (1995)   \n","4        5  Father of the Bride Part II (1995)   \n","\n","                                        genres  \n","0  Adventure|Animation|Children|Comedy|Fantasy  \n","1                   Adventure|Children|Fantasy  \n","2                               Comedy|Romance  \n","3                         Comedy|Drama|Romance  \n","4                                       Comedy  "],"text/html":["\n","  <div id=\"df-6e37c65a-ebb1-4058-a198-d4a687476e72\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>movieId</th>\n","      <th>title</th>\n","      <th>genres</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Toy Story (1995)</td>\n","      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Jumanji (1995)</td>\n","      <td>Adventure|Children|Fantasy</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Grumpier Old Men (1995)</td>\n","      <td>Comedy|Romance</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Waiting to Exhale (1995)</td>\n","      <td>Comedy|Drama|Romance</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Father of the Bride Part II (1995)</td>\n","      <td>Comedy</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e37c65a-ebb1-4058-a198-d4a687476e72')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6e37c65a-ebb1-4058-a198-d4a687476e72 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6e37c65a-ebb1-4058-a198-d4a687476e72');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["\n","# Take a look at ratings_df\n","ratings_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"Nd4L1Cuz0HDO","executionInfo":{"status":"ok","timestamp":1687935821544,"user_tz":-330,"elapsed":653,"user":{"displayName":"Ritik Maurya","userId":"07333108638949409589"}},"outputId":"a6860b14-82a3-4d33-c727-21d81c4d30a4"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   userId  movieId  rating  timestamp\n","0       1        1     4.0  964982703\n","1       1        3     4.0  964981247\n","2       1        6     4.0  964982224\n","3       1       47     5.0  964983815\n","4       1       50     5.0  964982931"],"text/html":["\n","  <div id=\"df-253c4bfb-c990-4f9a-bc94-435fe085cec1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>userId</th>\n","      <th>movieId</th>\n","      <th>rating</th>\n","      <th>timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4.0</td>\n","      <td>964982703</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4.0</td>\n","      <td>964981247</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>4.0</td>\n","      <td>964982224</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>47</td>\n","      <td>5.0</td>\n","      <td>964983815</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>50</td>\n","      <td>5.0</td>\n","      <td>964982931</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-253c4bfb-c990-4f9a-bc94-435fe085cec1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-253c4bfb-c990-4f9a-bc94-435fe085cec1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-253c4bfb-c990-4f9a-bc94-435fe085cec1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Movie ID to movie name mapping\n","movie_names = movies_df.set_index('movieId')['title'].to_dict()\n","n_users = len(ratings_df.userId.unique())\n","n_items = len(ratings_df.movieId.unique())\n","print(\"Number of unique users:\", n_users)\n","print(\"Number of unique movies:\", n_items)\n","print(\"The full rating matrix will have:\", n_users*n_items, 'elements.')\n","print('----------')\n","print(\"Number of ratings:\", len(ratings_df))\n","print(\"Therefore: \", len(ratings_df) / (n_users*n_items) * 100, '% of the matrix is filled.')\n","print(\"We have an incredibly sparse matrix to work with here.\")\n","print(\"And... as you can imagine, as the number of users and products grow, the number of elements will increase by n*2\")\n","print(\"You are going to need a lot of memory to work with global scale... storing a full matrix in memory would be a challenge.\")\n","print(\"One advantage here is that matrix factorization can realize the rating matrix implicitly, thus we don't need all the data\")\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AB43oKf10LJO","executionInfo":{"status":"ok","timestamp":1687935839389,"user_tz":-330,"elapsed":376,"user":{"displayName":"Ritik Maurya","userId":"07333108638949409589"}},"outputId":"b0621b94-7a7b-43a2-8c92-7e30c9d86cec"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of unique users: 610\n","Number of unique movies: 9724\n","The full rating matrix will have: 5931640 elements.\n","----------\n","Number of ratings: 100836\n","Therefore:  1.6999683055613624 % of the matrix is filled.\n","We have an incredibly sparse matrix to work with here.\n","And... as you can imagine, as the number of users and products grow, the number of elements will increase by n*2\n","You are going to need a lot of memory to work with global scale... storing a full matrix in memory would be a challenge.\n","One advantage here is that matrix factorization can realize the rating matrix implicitly, thus we don't need all the data\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","from torch.autograd import Variable\n","from tqdm import tqdm_notebook as tqdm\n","\n","class MatrixFactorization(torch.nn.Module):\n","    def __init__(self, n_users, n_items, n_factors=20):\n","        super().__init__()\n","        # create user embeddings\n","        self.user_factors = torch.nn.Embedding(n_users, n_factors) # think of this as a lookup table for the input.\n","        # create item embeddings\n","        self.item_factors = torch.nn.Embedding(n_items, n_factors) # think of this as a lookup table for the input.\n","        self.user_factors.weight.data.uniform_(0, 0.05)\n","        self.item_factors.weight.data.uniform_(0, 0.05)\n","\n","    def forward(self, data):\n","        # matrix multiplication\n","        users, items = data[:,0], data[:,1]\n","        return (self.user_factors(users)*self.item_factors(items)).sum(1)\n","    # def forward(self, user, item):\n","    # \t# matrix multiplication\n","    #     return (self.user_factors(user)*self.item_factors(item)).sum(1)\n","\n","    def predict(self, user, item):\n","        return self.forward(user, item)"],"metadata":{"id":"XcmOwzs00PfR","executionInfo":{"status":"ok","timestamp":1687935862966,"user_tz":-330,"elapsed":369,"user":{"displayName":"Ritik Maurya","userId":"07333108638949409589"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Creating the dataloader (necessary for PyTorch)\n","from torch.utils.data.dataset import Dataset\n","from torch.utils.data import DataLoader # package that helps transform your data to machine learning readiness\n","\n","# Note: This isn't 'good' practice, in a MLops sense but we'll roll with this since the data is already loaded in memory.\n","class Loader(Dataset):\n","    def __init__(self):\n","        self.ratings = ratings_df.copy()\n","\n","        # Extract all user IDs and movie IDs\n","        users = ratings_df.userId.unique()\n","        movies = ratings_df.movieId.unique()\n","\n","        #--- Producing new continuous IDs for users and movies ---\n","\n","        # Unique values : index\n","        self.userid2idx = {o:i for i,o in enumerate(users)}\n","        self.movieid2idx = {o:i for i,o in enumerate(movies)}\n","\n","        # Obtained continuous ID for users and movies\n","        self.idx2userid = {i:o for o,i in self.userid2idx.items()}\n","        self.idx2movieid = {i:o for o,i in self.movieid2idx.items()}\n","\n","        # return the id from the indexed values as noted in the lambda function down below.\n","        self.ratings.movieId = ratings_df.movieId.apply(lambda x: self.movieid2idx[x])\n","        self.ratings.userId = ratings_df.userId.apply(lambda x: self.userid2idx[x])\n","\n","\n","        self.x = self.ratings.drop(['rating', 'timestamp'], axis=1).values\n","        self.y = self.ratings['rating'].values\n","        self.x, self.y = torch.tensor(self.x), torch.tensor(self.y) # Transforms the data to tensors (ready for torch models.)\n","\n","    def __getitem__(self, index):\n","        return (self.x[index], self.y[index])\n","\n","    def __len__(self):\n","        return len(self.ratings)"],"metadata":{"id":"9huoH8T90VMC","executionInfo":{"status":"ok","timestamp":1687935883548,"user_tz":-330,"elapsed":375,"user":{"displayName":"Ritik Maurya","userId":"07333108638949409589"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["num_epochs = 128\n","cuda = torch.cuda.is_available()\n","\n","print(\"Is running on GPU:\", cuda)\n","\n","model = MatrixFactorization(n_users, n_items, n_factors=8)\n","print(model)\n","for name, param in model.named_parameters():\n","    if param.requires_grad:\n","        print(name, param.data)\n","# GPU enable if you have a GPU...\n","if cuda:\n","    model = model.cuda()\n","\n","# MSE loss\n","loss_fn = torch.nn.MSELoss()\n","\n","# ADAM optimizier\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","# Train data\n","train_set = Loader()\n","train_loader = DataLoader(train_set, 128, shuffle=True)\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MQw3vS1P0aFF","executionInfo":{"status":"ok","timestamp":1687935905962,"user_tz":-330,"elapsed":5525,"user":{"displayName":"Ritik Maurya","userId":"07333108638949409589"}},"outputId":"3e5bd1e8-1912-448b-f7bc-aa0af775202c"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Is running on GPU: True\n","MatrixFactorization(\n","  (user_factors): Embedding(610, 8)\n","  (item_factors): Embedding(9724, 8)\n",")\n","user_factors.weight tensor([[0.0202, 0.0141, 0.0405,  ..., 0.0095, 0.0188, 0.0214],\n","        [0.0144, 0.0323, 0.0283,  ..., 0.0211, 0.0034, 0.0300],\n","        [0.0141, 0.0463, 0.0099,  ..., 0.0257, 0.0325, 0.0177],\n","        ...,\n","        [0.0385, 0.0269, 0.0120,  ..., 0.0369, 0.0376, 0.0188],\n","        [0.0050, 0.0309, 0.0117,  ..., 0.0384, 0.0164, 0.0332],\n","        [0.0162, 0.0248, 0.0113,  ..., 0.0414, 0.0215, 0.0165]])\n","item_factors.weight tensor([[0.0098, 0.0270, 0.0226,  ..., 0.0064, 0.0109, 0.0498],\n","        [0.0088, 0.0192, 0.0496,  ..., 0.0016, 0.0203, 0.0175],\n","        [0.0408, 0.0414, 0.0331,  ..., 0.0388, 0.0149, 0.0204],\n","        ...,\n","        [0.0266, 0.0438, 0.0364,  ..., 0.0214, 0.0139, 0.0347],\n","        [0.0337, 0.0273, 0.0019,  ..., 0.0045, 0.0099, 0.0074],\n","        [0.0192, 0.0455, 0.0441,  ..., 0.0072, 0.0383, 0.0248]])\n"]}]},{"cell_type":"code","source":["for it in tqdm(range(num_epochs)):\n","    losses = []\n","    for x, y in train_loader:\n","         if cuda:\n","            x, y = x.cuda(), y.cuda()\n","            optimizer.zero_grad()\n","            outputs = model(x)\n","            loss = loss_fn(outputs.squeeze(), y.type(torch.float32))\n","            losses.append(loss.item())\n","            loss.backward()\n","            optimizer.step()\n","    print(\"iter #{}\".format(it), \"Loss:\", sum(losses) / len(losses))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["53430f8b82c5465c803dd2927e70bd0a","a46cfa4d155c49308bfc1fb1be4a3532","027516baa2b440719fb09fa0ebb87989","52e65dcd5bc349c79f1554130341fad2","54f97b8f351c46b4a2d2d33e4dd08a2c","82b2629549dd4611893d34478564dabe","3979b3ff99414539a2b4482f80e74483","67d6e0d1c47c4d0db8640b11ef0bfb99","d3a806a92cfb4cb5a8d1b35c12cdbd5f","637c64d3522947cf9426b72a693a121c","ae376510ddbe4e3cb522d33f69fed632"]},"id":"cfX3JmiF0gLI","executionInfo":{"status":"ok","timestamp":1687936114115,"user_tz":-330,"elapsed":189914,"user":{"displayName":"Ritik Maurya","userId":"07333108638949409589"}},"outputId":"f3114c61-ec91-48f1-a7ed-87269771770c"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-15-dad152416852>:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for it in tqdm(range(num_epochs)):\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/128 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53430f8b82c5465c803dd2927e70bd0a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["iter #0 Loss: 11.059868337539246\n","iter #1 Loss: 4.744196672124911\n","iter #2 Loss: 2.4754930454764876\n","iter #3 Loss: 1.720301261256794\n","iter #4 Loss: 1.3450936247703387\n","iter #5 Loss: 1.1281822509874546\n","iter #6 Loss: 0.9909375986925841\n","iter #7 Loss: 0.8996656787425733\n","iter #8 Loss: 0.837003511674513\n","iter #9 Loss: 0.7918942107388816\n","iter #10 Loss: 0.7590866846405915\n","iter #11 Loss: 0.7344303795226335\n","iter #12 Loss: 0.7158058645383356\n","iter #13 Loss: 0.7013555687620555\n","iter #14 Loss: 0.6903314971681779\n","iter #15 Loss: 0.6817494792305878\n","iter #16 Loss: 0.6749868901626108\n","iter #17 Loss: 0.6694933299712723\n","iter #18 Loss: 0.6658182543168213\n","iter #19 Loss: 0.6626439871748692\n","iter #20 Loss: 0.6605808507216159\n","iter #21 Loss: 0.6588419992382151\n","iter #22 Loss: 0.6576280321944789\n","iter #23 Loss: 0.6566178359204743\n","iter #24 Loss: 0.6556012313907522\n","iter #25 Loss: 0.6545361891237612\n","iter #26 Loss: 0.6539151119020989\n","iter #27 Loss: 0.6528881548473677\n","iter #28 Loss: 0.6518814934011038\n","iter #29 Loss: 0.6506902100849272\n","iter #30 Loss: 0.6489806370005995\n","iter #31 Loss: 0.6469323005016685\n","iter #32 Loss: 0.6445777377652638\n","iter #33 Loss: 0.6417328245597442\n","iter #34 Loss: 0.638241334993222\n","iter #35 Loss: 0.6339024250126127\n","iter #36 Loss: 0.6289343206486121\n","iter #37 Loss: 0.6229026752907008\n","iter #38 Loss: 0.6164146458285714\n","iter #39 Loss: 0.6088869319046815\n","iter #40 Loss: 0.6006209729664822\n","iter #41 Loss: 0.591522348940675\n","iter #42 Loss: 0.5819840757223556\n","iter #43 Loss: 0.5725711761467953\n","iter #44 Loss: 0.5626871742043399\n","iter #45 Loss: 0.5528925120981817\n","iter #46 Loss: 0.5431541191593645\n","iter #47 Loss: 0.5334687904279849\n","iter #48 Loss: 0.5242516482390728\n","iter #49 Loss: 0.5151770499908379\n","iter #50 Loss: 0.506570538364086\n","iter #51 Loss: 0.4979529414080121\n","iter #52 Loss: 0.49016601739801124\n","iter #53 Loss: 0.4823468887261328\n","iter #54 Loss: 0.4754874536077383\n","iter #55 Loss: 0.4686996023061917\n","iter #56 Loss: 0.4622173547404369\n","iter #57 Loss: 0.4562889954009032\n","iter #58 Loss: 0.4503421500173922\n","iter #59 Loss: 0.44499511778505924\n","iter #60 Loss: 0.44016482716965194\n","iter #61 Loss: 0.43509587240854497\n","iter #62 Loss: 0.4305348206822037\n","iter #63 Loss: 0.4260214497027966\n","iter #64 Loss: 0.42204354582401704\n","iter #65 Loss: 0.417908530058292\n","iter #66 Loss: 0.4140390942847063\n","iter #67 Loss: 0.41041564018593224\n","iter #68 Loss: 0.4068583407377834\n","iter #69 Loss: 0.4035046677563699\n","iter #70 Loss: 0.4002983003741291\n","iter #71 Loss: 0.39711662703359185\n","iter #72 Loss: 0.3942680895555443\n","iter #73 Loss: 0.3914654620256521\n","iter #74 Loss: 0.38889029508617323\n","iter #75 Loss: 0.3863768656809015\n","iter #76 Loss: 0.3837702340696971\n","iter #77 Loss: 0.3811820324718347\n","iter #78 Loss: 0.378881862547797\n","iter #79 Loss: 0.3767363119889334\n","iter #80 Loss: 0.37474022550404373\n","iter #81 Loss: 0.37261756244801025\n","iter #82 Loss: 0.37084564939141273\n","iter #83 Loss: 0.3687566210359789\n","iter #84 Loss: 0.36712989436112686\n","iter #85 Loss: 0.36515304992722375\n","iter #86 Loss: 0.3637720709902986\n","iter #87 Loss: 0.3622053042432378\n","iter #88 Loss: 0.36065823830626337\n","iter #89 Loss: 0.3592763292570102\n","iter #90 Loss: 0.35786591273576474\n","iter #91 Loss: 0.35618401214782963\n","iter #92 Loss: 0.3550763270500953\n","iter #93 Loss: 0.35376707842658617\n","iter #94 Loss: 0.3525125712799239\n","iter #95 Loss: 0.3512905610318716\n","iter #96 Loss: 0.35010757571473944\n","iter #97 Loss: 0.3491254280401668\n","iter #98 Loss: 0.3479095284406304\n","iter #99 Loss: 0.34701738115116426\n","iter #100 Loss: 0.3461608721066247\n","iter #101 Loss: 0.34493036793195053\n","iter #102 Loss: 0.34412241670383414\n","iter #103 Loss: 0.3430399107864968\n","iter #104 Loss: 0.3422414334065418\n","iter #105 Loss: 0.3414053087912235\n","iter #106 Loss: 0.34067023581432815\n","iter #107 Loss: 0.33968617700910203\n","iter #108 Loss: 0.3389521085179699\n","iter #109 Loss: 0.3384079518089742\n","iter #110 Loss: 0.3376271236631168\n","iter #111 Loss: 0.33680584945427583\n","iter #112 Loss: 0.33601826936157825\n","iter #113 Loss: 0.33549705200691515\n","iter #114 Loss: 0.3348845600287624\n","iter #115 Loss: 0.334177193756636\n","iter #116 Loss: 0.3334613740822385\n","iter #117 Loss: 0.3326891397083471\n","iter #118 Loss: 0.3322705585263707\n","iter #119 Loss: 0.3316121041245267\n","iter #120 Loss: 0.33115882209034136\n","iter #121 Loss: 0.3305883902091968\n","iter #122 Loss: 0.3300511364631241\n","iter #123 Loss: 0.32943668161627604\n","iter #124 Loss: 0.32904614629176665\n","iter #125 Loss: 0.3285901468757748\n","iter #126 Loss: 0.3280228976784321\n","iter #127 Loss: 0.3275750204731668\n"]}]},{"cell_type":"code","source":["# By training the model, we will have tuned latent factors for movies and users.\n","c = 0\n","uw = 0\n","iw = 0\n","for name, param in model.named_parameters():\n","    if param.requires_grad:\n","        print(name, param.data)\n","        if c == 0:\n","          uw = param.data\n","          c +=1\n","        else:\n","          iw = param.data\n","        #print('param_data', param_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3RtTKhzM1Sts","executionInfo":{"status":"ok","timestamp":1687936130940,"user_tz":-330,"elapsed":363,"user":{"displayName":"Ritik Maurya","userId":"07333108638949409589"}},"outputId":"6b08d221-d3f2-4200-fe26-6bbb58b26ff3"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["user_factors.weight tensor([[ 1.1714,  1.2155,  1.6330,  ...,  0.8714,  0.7295,  0.9161],\n","        [ 0.4525,  1.4320,  1.2468,  ...,  1.2511,  1.7483,  1.0784],\n","        [ 1.4384,  0.7942, -0.8336,  ...,  0.8895, -0.3066,  2.4307],\n","        ...,\n","        [ 2.1541,  1.9686,  0.3405,  ...,  0.8026,  2.0062, -0.5718],\n","        [ 1.0348,  1.3658,  1.2085,  ...,  0.5914,  1.3074,  0.4342],\n","        [ 1.5803,  0.4020,  1.5250,  ...,  1.3706,  1.1648,  0.6354]],\n","       device='cuda:0')\n","item_factors.weight tensor([[0.3165, 0.4128, 0.6812,  ..., 0.3619, 0.4754, 0.7769],\n","        [0.0112, 0.3017, 0.5206,  ..., 1.0107, 0.1770, 0.5895],\n","        [0.6631, 0.4875, 0.6845,  ..., 0.5992, 0.3882, 0.0653],\n","        ...,\n","        [0.3519, 0.3520, 0.3619,  ..., 0.3464, 0.3409, 0.3596],\n","        [0.4290, 0.4108, 0.3968,  ..., 0.4004, 0.4064, 0.4054],\n","        [0.4014, 0.4161, 0.4263,  ..., 0.3910, 0.4224, 0.4068]],\n","       device='cuda:0')\n"]}]},{"cell_type":"code","source":["trained_movie_embeddings = model.item_factors.weight.data.cpu().numpy()"],"metadata":{"id":"MVA92LQE1W_-","executionInfo":{"status":"ok","timestamp":1687936149483,"user_tz":-330,"elapsed":372,"user":{"displayName":"Ritik Maurya","userId":"07333108638949409589"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["len(trained_movie_embeddings) # unique movie factor weights\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VnImD1bI1ay4","executionInfo":{"status":"ok","timestamp":1687936162076,"user_tz":-330,"elapsed":405,"user":{"displayName":"Ritik Maurya","userId":"07333108638949409589"}},"outputId":"115a3dec-453f-4183-928e-76393bf0e070"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9724"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["from sklearn.cluster import KMeans\n","# Fit the clusters based on the movie weights\n","kmeans = KMeans(n_clusters=10, random_state=0).fit(trained_movie_embeddings)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lj2MxnfJ1eOA","executionInfo":{"status":"ok","timestamp":1687936180211,"user_tz":-330,"elapsed":2149,"user":{"displayName":"Ritik Maurya","userId":"07333108638949409589"}},"outputId":"67a8e25a-2f4c-49d2-8dec-7832c73d2b11"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["'''It can be seen here that the movies that are in the same cluster tend to have\n","similar genres. Also note that the algorithm is unfamiliar with the movie name\n","and only obtained the relationships by looking at the numbers representing how\n","users have responded to the movie selections.'''\n","for cluster in range(10):\n","  print(\"Cluster #{}\".format(cluster))\n","  movs = []\n","  for movidx in np.where(kmeans.labels_ == cluster)[0]:\n","    movid = train_set.idx2movieid[movidx]\n","    rat_count = ratings_df.loc[ratings_df['movieId']==movid].count()[0]\n","    movs.append((movie_names[movid], rat_count))\n","  for mov in sorted(movs, key=lambda tup: tup[1], reverse=True)[:10]:\n","    print(\"\\t\", mov[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bItljxFD1i4Q","executionInfo":{"status":"ok","timestamp":1687936209876,"user_tz":-330,"elapsed":13824,"user":{"displayName":"Ritik Maurya","userId":"07333108638949409589"}},"outputId":"87dfb141-b0ef-424a-c2d2-04fec158c2dd"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Cluster #0\n","\t Ace Ventura: Pet Detective (1994)\n","\t Dumb & Dumber (Dumb and Dumber) (1994)\n","\t Babe (1995)\n","\t Home Alone (1990)\n","\t Bourne Identity, The (2002)\n","\t Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n","\t Harry Potter and the Prisoner of Azkaban (2004)\n","\t Star Trek: First Contact (1996)\n","\t Bourne Supremacy, The (2004)\n","\t Maverick (1994)\n","Cluster #1\n","\t Schindler's List (1993)\n","\t Toy Story (1995)\n","\t E.T. the Extra-Terrestrial (1982)\n","\t Four Weddings and a Funeral (1994)\n","\t Casablanca (1942)\n","\t Wizard of Oz, The (1939)\n","\t Big (1988)\n","\t Spirited Away (Sen to Chihiro no kamikakushi) (2001)\n","\t When Harry Met Sally... (1989)\n","\t Rear Window (1954)\n","Cluster #2\n","\t Forrest Gump (1994)\n","\t Shawshank Redemption, The (1994)\n","\t Silence of the Lambs, The (1991)\n","\t Matrix, The (1999)\n","\t Jurassic Park (1993)\n","\t Terminator 2: Judgment Day (1991)\n","\t Star Wars: Episode V - The Empire Strikes Back (1980)\n","\t Usual Suspects, The (1995)\n","\t Seven (a.k.a. Se7en) (1995)\n","\t Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\n","Cluster #3\n","\t Batman & Robin (1997)\n","\t Godzilla (1998)\n","\t Spy Hard (1996)\n","\t Super Mario Bros. (1993)\n","\t Honey, I Blew Up the Kid (1992)\n","\t Rocky V (1990)\n","\t Another Stakeout (1993)\n","\t Volcano (1997)\n","\t Karate Kid, Part III, The (1989)\n","\t Vertical Limit (2000)\n","Cluster #4\n","\t Apollo 13 (1995)\n","\t Batman (1989)\n","\t Dances with Wolves (1990)\n","\t Die Hard: With a Vengeance (1995)\n","\t Stargate (1994)\n","\t Pretty Woman (1990)\n","\t GoldenEye (1995)\n","\t Truman Show, The (1998)\n","\t Spider-Man (2002)\n","\t Austin Powers: The Spy Who Shagged Me (1999)\n","Cluster #5\n","\t Star Wars: Episode IV - A New Hope (1977)\n","\t Braveheart (1995)\n","\t Star Wars: Episode VI - Return of the Jedi (1983)\n","\t Fugitive, The (1993)\n","\t Mission: Impossible (1996)\n","\t Die Hard (1988)\n","\t Terminator, The (1984)\n","\t Aliens (1986)\n","\t Blade Runner (1982)\n","\t Clear and Present Danger (1994)\n","Cluster #6\n","\t Pulp Fiction (1994)\n","\t Fight Club (1999)\n","\t American Beauty (1999)\n","\t Fargo (1996)\n","\t Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n","\t Memento (2000)\n","\t Monty Python and the Holy Grail (1975)\n","\t Léon: The Professional (a.k.a. The Professional) (Léon) (1994)\n","\t Kill Bill: Vol. 1 (2003)\n","\t Eternal Sunshine of the Spotless Mind (2004)\n","Cluster #7\n","\t Independence Day (a.k.a. ID4) (1996)\n","\t True Lies (1994)\n","\t Mrs. Doubtfire (1993)\n","\t Star Wars: Episode I - The Phantom Menace (1999)\n","\t Titanic (1997)\n","\t Batman Forever (1995)\n","\t Twister (1996)\n","\t Rock, The (1996)\n","\t Net, The (1995)\n","\t Star Trek: Generations (1994)\n","Cluster #8\n","\t Speed (1994)\n","\t Men in Black (a.k.a. MIB) (1997)\n","\t Mask, The (1994)\n","\t Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n","\t Beauty and the Beast (1991)\n","\t X-Men (2000)\n","\t Harry Potter and the Chamber of Secrets (2002)\n","\t Matrix Reloaded, The (2003)\n","\t Iron Man (2008)\n","\t Mummy, The (1999)\n","Cluster #9\n","\t Waterworld (1995)\n","\t Interview with the Vampire: The Vampire Chronicles (1994)\n","\t Natural Born Killers (1994)\n","\t Demolition Man (1993)\n","\t Starship Troopers (1997)\n","\t Matrix Revolutions, The (2003)\n","\t Shutter Island (2010)\n","\t Sense and Sensibility (1995)\n","\t Blair Witch Project, The (1999)\n","\t Coneheads (1993)\n"]}]}]}